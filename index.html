<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Weirong Chen</title>

  <meta name="author" content="Weirong Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/x-icon" href="images/icon.svg">
</head>

<body>
  <table
    style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <!-- 1 INTRO -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Weirong Chen</name>
                  </p>
                  <p align="justify">
                    Hi, I am a first-year PhD student at <a href="https://www.tum.de/en/">Technical University of Munich</a> and <a href="https://www.ox.ac.uk/">University of Oxford</a> under <a href="https://ellis.eu/phd-postdoc">ELLIS</a>,
                    supervised by Prof. <a href="https://cvg.cit.tum.de/members/cremers">Daniel Cremers</a> and Prof. <a href="https://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>.
                  </p>
                  <p align="justify">
                    Previously, I received my Master's degree in Computer Science from <a href="https://ethz.ch/en.html">ETH Zurich</a> advised by Prof. <a href="https://people.inf.ethz.ch/pomarc/">Marc Pollefeys</a>.
                    I worked on 3D vision projects at <a href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-zurich/">Microsoft Mixed Reality & AI Lab Zurich</a>, <a href="https://cvg.ethz.ch/">Computer Vision and Geometry Group (CVG)</a>, and <a href="https://vision.ee.ethz.ch/">Computer Vision Lab (CVL)</a>.
                    Before this, I obtained my Bachelor's degree in Computer Science from <a href="https://www.cuhk.edu.hk/">The Chinese University of Hong Kong</a> 
                    and interned at <a href="https://www.sensetime.com/en">SenseTime Research</a>.
      
                  </p>
                  <p align="justify">
                    My research interests lie in the interplay between computer vision and 3D geometry, with a focus on visual localization, 3D/4D reconstruction, and neural scene representations. 
                    I am also broadly interested in object-level perception, egocentric vision, and spatial computing.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:weirong.chen@tum.de">Email</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?hl=en&user=50yGm5wAAAAJ">Google Scholar</a> &nbsp/&nbsp
                    <a href="https://github.com/chiaki530">Github</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/weirong-chen-879488170/">Linkedin</a> 
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/photo_linkedin.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/photo_linkedin.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                </td>
              </tr>
            </tbody>
          </table>
           
          <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr >
              <td style="padding-left:20px;width:45%;vertical-align:middle;text-align:middle">
                <p>
                  [<strong>10-2023</strong>] &nbsp&nbsp 
                  I join <a href="https://www.tum.de/en/">Technical University of Munich</a> as an ELLIS PhD student.
                </br>
                  [<strong>08-2023</strong>] &nbsp&nbsp 
                  I finish my Master's Thesis at <a href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-zurich/">Microsoft Mixed Reality & AI Lab Zurich</a>.
                </p>
              </td>
              </tr>
          </tbody>
          </table>
          <p></p>

          <!-- 2 Research -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- 2.3 Ref-NPR -->
              
              <tr class="single_element" style="width:70%">
                <td style="padding:20px;width:35%;vertical-align:middle;text-align:middle" onmouseout="leapvo_stop()" onmouseover="leapvo_start()">
                  <div class="one" style="display: inline;">
                    <div class="two" id="leapvo_image" style="display: inline;">
                      <img src="images/leapvo_anime.gif" alt="Results 2 for twoviewsfm" width="320" width="100%" vertical-align="middle">
                    </div>
                    <img src="images/leapvo_static.jpg" alt="Results 1 for twoviewsfm" width="320" width="100%" vertical-align="middle">
                  </div>
                  <script type="text/javascript">
                    function leapvo_start() {
                      document.getElementById('leapvo_image').style.opacity = "1";
                    }

                    function leapvo_stop() {
                      document.getElementById('leapvo_image').style.opacity = "0";
                    }
                    refnpr_stop()
                  </script>
                </td>
                <td style="padding:20px;width:65%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2401.01887">
                  <papertitle>LEAP-VO: Long-term Effective Any Point Tracking for Visual Odometry
                  </papertitle>
                </a>
                  <br>
                  <strong>Weirong Chen</strong>,
                  <a href="https://clthegoat.github.io/">Le Chen</a>,
                  <a href="https://rui2016.github.io/">Rui Wang</a>,
                  <a href="https://people.inf.ethz.ch/pomarc/">Marc Pollefeys</a>
                  <br>
                  <p></p>
                  <em>Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>)</em>, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2401.01887">arXiv</a>
                  /
                  <a href="https://chiaki530.github.io/projects/leapvo">Project Page</a>
                  <p></p>
                  <p align="justify">
                    A robust visual odometry system leveraging long-term point tracking to build that excels in managing occlusions and dynamic environments.
                  </p>
                </td>
              </tr>

               
              <tr class="single_element" style="width:70%">
                <td style="padding:20px;width:35%;vertical-align:middle;text-align:middle" onmouseout="escrnet_stop()" onmouseover="escrnet_start()">
                  <div class="one" style="display: inline;">
                    <div class="two" id="escrnet_image" style="display: inline;">
                      <img src="images/escrnet_anime.gif" alt="Results 2 for twoviewsfm" width="320" height="180" vertical-align="middle">
                    </div>
                    <img src="images/escrnet_static.jpg" alt="Results 1 for twoviewsfm" width="320" height="180" vertical-align="middle">
                  </div>
                  <script type="text/javascript">
                    function escrnet_start() {
                      document.getElementById('escrnet_image').style.opacity = "1";
                    }

                    function escrnet_stop() {
                      document.getElementById('escrnet_image').style.opacity = "0";
                    }
                    refnpr_stop()
                  </script>
                </td>
                <td style="padding:20px;width:65%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2310.06984">
                  <papertitle>Leveraging Neural Radiance Fields for Uncertainty-Aware Visual Localization
                  </papertitle>
                </a>
                  <br>
                  <a href="https://clthegoat.github.io/">Le Chen</a>,
                  <strong>Weirong Chen</strong>,
                  <a href="https://rui2016.github.io/">Rui Wang</a>,
                  <a href="https://people.inf.ethz.ch/pomarc/">Marc Pollefeys</a>
                  <br>
                  <p></p>
                  <em>International Conference on Robotics and Automation (<strong>ICRA</strong>)</em>, 2024
                  <br>
                  <!-- /
                  <a href="https://huggingface.co/spaces/CVPR/Bamboo_ViT-B16_demo">Demo</a>
                  /
                  <a href="https://github.com/Davidzhangyuanhan/Bamboo">Code</a>
                  <img alt="GitHub Repo stars"
                    src="https://img.shields.io/github/stars/Davidzhangyuanhan/Bamboo?style=social"> -->
                  <a href="https://arxiv.org/abs/2310.06984">arXiv</a>
                  /
                  <a href="https://drive.google.com/file/d/1YUMlngGFvYY_iPNu9wMA1woxw8432qXh/view">Video</a>
                  <p></p>
                  <p align="justify">
                    A visual localization pipeline using rendered RGB-D data from NeRF, uncertainty-guided novel view selection, and evidential scene coordinate regression. 
                  </p>
                </td>
              </tr>



               
              <tr class="single_element" style="width:70%">
                <td style="padding:20px;width:35%;vertical-align:middle;text-align:middle" onmouseout="refnpr_stop()" onmouseover="refnpr_start()">
                  <div class="one" style="display: inline;">
                    <div class="two" id="twoviewsfm_image" style="display: inline;">
                      <img src="images/twoviewsfm22_result1.png" alt="Results 2 for twoviewsfm" width="320" height="180" vertical-align="middle">
                    </div>
                    <img src="images/twoviewsfm22_result.png" alt="Results 1 for twoviewsfm" width="320" height="180" vertical-align="middle">
                  </div>
                  <script type="text/javascript">
                    function refnpr_start() {
                      document.getElementById('twoviewsfm_image').style.opacity = "1";
                    }

                    function refnpr_stop() {
                      document.getElementById('twoviewsfm_image').style.opacity = "0";
                    }
                    refnpr_stop()
                  </script>
                </td>
                <td style="padding:20px;width:65%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2302.00523">
                  <papertitle>Uncertainty-Driven Dense Two-View Structure from Motion
                  </papertitle>
                </a>
                  <br>
                  <strong>Weirong Chen</strong>,
                  <a href="https://suryanshkumar.github.io/">Suryansh Kumar</a>,
                  <a href="https://www.yf.io/">Fisher Yu</a>
                  <br>
                  <p></p>
                  <em>International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2023 <font color="red"><strong>(Oral)</strong></font>
                  <br>
                  <em>IEEE Robotics and Automation Letters (<strong>RA-L</strong>)</em>, 2023
                  <br>
                  <!-- /
                  <a href="https://huggingface.co/spaces/CVPR/Bamboo_ViT-B16_demo">Demo</a>
                  /
                  <a href="https://github.com/Davidzhangyuanhan/Bamboo">Code</a>
                  <img alt="GitHub Repo stars"
                    src="https://img.shields.io/github/stars/Davidzhangyuanhan/Bamboo?style=social"> -->
                  <a href="https://arxiv.org/abs/2302.00523">arXiv</a>
                  /
                  <a href="https://www.vis.xyz/pub/dtv-sfm/">Project Page</a>
                  /
                  <a href="https://www.youtube.com/watch?v=RUlfqB587Fw&ab_channel=SuryanshKumar">Video</a>
                  <p></p>
                  <p align="justify">
                    An accurate and reliable pipeline for dense two-view SfM using weighted bundle adjustment with robust outlier filtering and learning-based confidence modeling.
                  </p>
                </td>
              </tr>

              <!-- 2.2 Bamboo -->           
              <tr class="single_element" style="width:70%">
                <td style="padding:20px;width:35%;vertical-align:middle;text-align:middle" onmouseout="bamboo_stop()" onmouseover="bamboo_start()">
                  <div class="one" style="display: inline;">
                    <div class="two" id="acmmm_image" style="display: inline;">
                      <img src="images/mm20_1.png" alt="Cover Image for ACMMM" width="320" height="180" vertical-align="middle">
                    </div>
                    <img src="images/mm20_2.png" alt="Cover Image for ACMMM" width="320" height="180" vertical-align="middle">
                  </div>
                  <script type="text/javascript">
                    function bamboo_start() {
                      document.getElementById('acmmm_image').style.opacity = "1";
                    }

                    function bamboo_stop() {
                      document.getElementById('acmmm_image').style.opacity = "0";
                    }
                    bamboo_stop()
                  </script>
                </td>
                <td style="padding:20px;width:65%;vertical-align:middle">
                  <a href="data/acmmm2020_webly.pdf">
                    <papertitle>Webly Supervised Image Classification with Metadata: Automatic Noisy Label Correction via Visual-Semantic Graph
                    </papertitle>
                  </a>
                  <br>
                  <a href="https://jingkang50.github.io/">Jingkang Yang</a>*,
                  <strong>Weirong Chen</strong>*,
                  <a href="https://scholar.google.com.hk/citations?user=PnNAAasAAAAJ&hl=en">Litong Feng</a>,
                  <a href="https://yanxp.github.io/">Xiaopeng Yan</a>,
                  <a href="https://openreview.net/profile?id=~Huabin_Zheng1">Huabin Zheng</a>,
                  <a href="http://www.statfe.com/">Wayne Zhang</a>
                  <br>
                  (* equal contribution)
                  <p></p>
                  <em>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</em>, 2020 <font color="red"><strong>(Oral)</strong></font>
                  <!-- (* equal contribution) -->
                  <br>
                  <a href="https://arxiv.org/abs/2010.05864">arXiv</a>
                  /
                  <a href="data/acmmm20_slide.pdf">Slides</a>
                  <p></p>
                  <p align="justify">
                    Webly supervised learning for semantic label confusion using visual-semantic graph with metadata-aware anchor selection and GNN-based label propagation.
                  </p>
                </td>
              </tr>

              <!-- 2.1 CMT -->
              <tr class="single_element" style="width:70%">
                <td style="padding:20px;width:35%;vertical-align:middle;text-align:middle" onmouseout="scc_stop()" onmouseover="scc_start()">
                  <div class="one" style="display: inline;">
                    <div class="two" id="scc_image" style="display: inline;">
                      <img src="images/eccv20_2.png" alt="Annimation for SCC" width="320" height="180" vertical-align="middle">
                    </div>
                    <img src="images/eccv20_1.png" alt="Cover Image for SCC" width="320" height="180" vertical-align="middle">
                  </div>
                  <script type="text/javascript">
                    function scc_start() {
                      document.getElementById('scc_image').style.opacity = "1";
                    }
                    function scc_stop() {
                      document.getElementById('scc_image').style.opacity = "0";
                    }
                  </script>
                </td>
                <td style="padding:20px;width:65%;vertical-align:middle">
                  <a href="data/eccv2020_webly.pdf">
                    <papertitle>Webly Supervised Image Classification with Self-Contained Confidence</papertitle>
                  </a>
                  <br>
                  <a href="https://jingkang50.github.io/">Jingkang Yang</a>,
                  <a href="https://scholar.google.com.hk/citations?user=PnNAAasAAAAJ&hl=en">Litong Feng</a>,
                  <strong>Weirong Chen</strong>,
                  <a href="https://yanxp.github.io/">Xiaopeng Yan</a>,
                  <a href="https://openreview.net/profile?id=~Huabin_Zheng1">Huabin Zheng</a>,
                  <a href="http://luoping.me/">Ping Luo</a>,
                  <a href="http://www.statfe.com/">Wayne Zhang</a>
                  <br>
                  <p></p>
                  <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/2008.11894">arXiv</a>
                  /
                  <a href="https://github.com/bigvideoresearch/SCC">Code</a>
                  <p></p>
                  <p align="justify">
                    Webly supervised learning for noisy label classification via sample-wise web label correction with model confidence and pseudo machine label.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <p></p>
          
          <table
          style="width:100%;border:0px;border-spacing:10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:0px;width:100%;vertical-align:middle">
                <heading>Other Projects</heading>
              </td>
            </tr>
          </tbody>
        </table>

        <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>

            <!-- 2.3 Ref-NPR -->
            <tr class="single_element" style="width:70%">
              <td style="padding:20px;width:35%;vertical-align:middle;text-align:middle" onmouseout="colmapslam_stop()" onmouseover="colmapslam_start()">
                <div class="one" style="display: inline;">
                  <div class="two" id="colmapslam_image" style="display: inline;">
                    <img src="images/3dv_anime.gif" alt="Results 2 for colmapslam" width="320" height="180" vertical-align="middle">
                  </div>
                  <img src="images/3dv_static.png" alt="Results 1 for colmapslam" width="320" height="180" vertical-align="middle">
                </div>
                <script type="text/javascript">
                  function colmapslam_start() {
                    document.getElementById('colmapslam_image').style.opacity = "1";
                  }

                  function colmapslam_stop() {
                    document.getElementById('colmapslam_image').style.opacity = "0";
                  }
                  refnpr_stop()
                </script>
              </td>
              <td style="padding:20px;width:65%;vertical-align:middle">
                <papertitle>An Efficient and Accurate Offline Python SLAM using COLMAP
                </papertitle>
                <br>Conference
                with Yifei Liu, Kexin Shi, Yidan Gao
                <br>
                Supervised by <a href="https://psarlin.com/">Paul‑Edouard Sarlin</a> and <a href="https://people.inf.ethz.ch/pomarc/">Marc Pollefeys</a>
                <p></p>
                <a href="https://drive.google.com/file/d/1SUAnv6l69lDIuFu8iadkP70DrkNChG5t/view?usp=sharing">Demo (KITTI)</a>
                /
                <a href="https://drive.google.com/file/d/1BCULzlK0AAw0mVcwnLeyrUHpga8KBuBu/view?usp=sharing">Demo (Zurich)</a>
                /
                <a href="data/3dv_report.pdf">Report</a>
                <p></p>
                <p align="justify">
                  A robust and highly-extensible Python SLAM built on pycolmap; achieved better pose accuracy and significant speed improvement compared to COLMAP.
                </p>
              </td>
            </tr>

            <tr class="single_element" style="width:70%">
              <td style="padding:20px;width:35%;vertical-align:middle;text-align:middle" onmouseout="mr_stop()" onmouseover="mr_start()">
                <div class="one" style="display: inline;">
                  <div class="two" id="mr_image" style="display: inline;">
                    <img src="images/mr_anime.gif" alt="Results 2 for pytorch3dvr" width="320" height="180" vertical-align="middle">
                  </div>
                  <img src="images/mr_pipeline.png" alt="Results 1 for pytorch3dvr" width="320" height="180" vertical-align="middle">
                </div>
                <script type="text/javascript">
                  function mr_start() {
                    document.getElementById('mr_image').style.opacity = "1";
                  }

                  function mr_stop() {
                    document.getElementById('mr_image').style.opacity = "0";
                  }
                  refnpr_stop()
                </script>
              </td>
              <td style="padding:20px;width:65%;vertical-align:middle">
                <papertitle>Real-time Photorealistic Neural Rendering in VR
                </papertitle>
                <br>
                <!-- <em>Course Project</em> in <a href="https://www.cvg.ethz.ch/teaching/mrlab/2021/index.php">Mixed Reality@ETH CVG</a>, 
                supervised by Dr. <a href="https://scholar.google.de/citations?user=xSywCzAAAAAJ&hl=en">Sergey Prokudin</a> -->
                with Shengqu Cai, Mingyang Song, Tianfu Wang<br>
                Supervised by <a href="https://scholar.google.de/citations?user=xSywCzAAAAAJ&hl=en">Sergey Prokudin</a> 
                <br>
                <p></p>
                <a href="https://drive.google.com/file/d/1kyHt-a0Jez78DYeuOTsv-oEHGvjLQuea/view?usp=sharing">Demo</a>
                /
                <a href="data/mr_report.pdf">Report</a>
                /
                <a href="https://github.com/Chiaki530/barracuda-neural-rendering-vr">Code</a>
                
                <p></p>
                <p align="justify">
                  A general neural rendering pipeline for photorealistic synthesis in VR devices in real-time; demo included human neural rendering and scene style transfer.
                </p>
              </td>
            </tr> 

            
            <tr class="single_element" style="width:70%">
              <td style="padding:20px;width:35%;vertical-align:middle;text-align:middle" onmouseout="pytorch3dvr_stop()" onmouseover="pytorch3dvr_start()">
                <div class="one" style="display: inline;">
                  <div class="two" id="pytorch3dvr_image" style="display: inline;">
                    <img src="images/pytorch3d_vr_anime.gif" alt="Results 2 for pytorch3dvr" width="320" height="180" vertical-align="middle">
                  </div>
                  <img src="images/pytorch3d_vr_pipeline.png" alt="Results 1 for pytorch3dvr" width="320" height="180" vertical-align="middle">
                </div>
                <script type="text/javascript">
                  function pytorch3dvr_start() {
                    document.getElementById('pytorch3dvr_image').style.opacity = "1";
                  }

                  function pytorch3dvr_stop() {
                    document.getElementById('pytorch3dvr_image').style.opacity = "0";
                  }
                  refnpr_stop()
                </script>
              </td>
              <td style="padding:20px;width:65%;vertical-align:middle">
                <papertitle>Pytorch3D VR Viewer
                </papertitle>
                <br>
                <em>Research Assistant</em> at <a href="https://vlg.inf.ethz.ch/">ETH VLG</a>
                <br>
                Supervised by <a href="https://scholar.google.de/citations?user=xSywCzAAAAAJ&hl=en">Sergey Prokudin</a> and <a href="https://vlg.inf.ethz.ch/team/Prof-Dr-Siyu-Tang.html">Siyu Tang</a>
                <br>
                <p></p>
                <a href="https://github.com/Chiaki530/pytorch3d-vr-viewer">Code</a>
                <p></p>
                <p align="justify">
                  A customizable VR neural rendering viewer for evaluating and developing neural rendering methods in Python; built on Pytorch3D and OpenVR. 
                </p>
              </td>
            </tr>



          </tbody>
        </table>

        <p></p>
        <p></p>
          <!-- 3 Experiences -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tbody>
              <tr>
                <td>
                  <heading>Experiences</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <p></p>
          <table style="border-spacing:20px 0px;">
            <tbody>
              <tr>
                <td style="padding:10px;width:35%;text-align:left">
                  <b><a href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-zurich/">Microsoft Mixed Reality & AI Lab Zurich</a></b>
                </td>
                <td style="padding:0px;width:35%;text-align:left">
                  <b>Mentors</b>: <a href="https://rui2016.github.io/">Rui Wang</a>,
                  <a href="https://people.inf.ethz.ch/pomarc/">Marc Pollefeys</a>
                </td>
                <td style="padding:0px;width:20%;text-align:left">
                  <strong>11/2022 - 08/2023</strong>
                </td>
              </tr>
              <tr>
                <td style="padding:10px;width:35%;text-align:left">
                  <b><a href="https://vlg.inf.ethz.ch/">ETH Computer Vision and Learning Group</a></b>
                </td>
                <td style="padding:0px;width:35%;text-align:left">
                  <b>Mentors</b>: <a href="https://scholar.google.de/citations?user=xSywCzAAAAAJ&hl=en">Sergey Prokudin</a>, 
                  <a href="https://vlg.inf.ethz.ch/team/Prof-Dr-Siyu-Tang.html">Siyu Tang</a>
                </td>
                <td style="padding:0px;width:20%;text-align:left">
                  <strong>06/2022 - 09/2022</strong>
                </td>
              </tr>
              <tr>
                <td style="padding:10px;width:35%;text-align:left">
                  <b><a href="https://www.sensetime.com/en/technology-achievements">SenseTime Research</a></b>
                </td>
                <td style="padding:0px;width:35%;text-align:left">
                  <b>Mentors</b>: <a href="https://scholar.google.com.hk/citations?user=PnNAAasAAAAJ&hl=en">Litong Feng</a>, <a
                    href="http://www.statfe.com/">Wayne Zhang</a>
                </td>
                <td style="padding:0px;width:20%;text-align:left">
                  <strong>05/2019 - 09/2019</strong>
                </td>
              </tr>
            </tbody>
          </table>

          <p></p>
          <p></p>
          <p></p>
          <!-- 4 HonorsAndAwards -->
          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tbody>
              <tr>
                <td>
                  <heading>Selected Awards</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <ul> 
            <li>
                <a href="https://data.vision.ee.ethz.ch/cvl/webvision/2019/challenge_results.html">First Runner-up Award</a>, <b>CVPR 2019 WebVision Challenge</b>
            </li>
            <li>
                CUHK Faculty of Engineering, Dean’s List, <b>2017, 2018, 2020</b>
            </li>
            <li>
                CUHK CSE Outstanding Academic Performance Award, <b>2019, 2020</b>
            </li>
            <li>
                CUHK ELITE Stream Scholarship, <b>2017, 2018, 2020</b>
            </li>
          </ul> -->

          <p></p>
          <p></p>

          <!-- 5 Teaching -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tbody>
              <tr>
                <td>
                  <heading>Academic Services</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <ul> 
            <li>
               <strong>Conference Reviewer</strong>: CVPR
            </li>
          </ul>
          <!-- <table style="border-spacing:10px 0px;">
            <tbody>
              <tr>
                <td style="padding:10px;width:35%;text-align:left">
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; AIST2010 <b>|</b> Introduction to Computer Music <b>|</b> 2022 Fall
                </td>
              </tr>
              <tr>
                <td style="padding:10px;width:35%;text-align:left">
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; AIST3110 <b>|</b> Music Information Retrieval <b>|</b> 2023 Spring
                </td>
              </tr>
            </tbody>
          </table> -->

          <!-- 6 Ending -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tbody>
            <tr>
              <td style="padding:0px">
               
              </td>
            </tr>
          </tbody></table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <center>
                    <div id="clustrmaps-widget" style="width:10%" hidden>
                      <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=ZjfeKr39ZSWC0y4jv0UdZ77bVMagCKUTmfDnTEcjaq8"></script>
                      <!-- <a href="https://clustrmaps.com/site/1bqpr"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=ZjfeKr39ZSWC0y4jv0UdZ77bVMagCKUTmfDnTEcjaq8&cl=ffffff" /></a> -->
                    </div>
                  </center>
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Last updated: Feb 2024
                    <br>
                    Web page design credit to <a href="https://jonbarron.info" style="font-size: 14px">Jon Barron</a> and <a href="https://julianjuaner.github.io/" style="font-size: 14px">Yuechen Zhang</a>
                    <br>
                    <!-- Avatar style credit to <a href="https://www.shaotengliu.com/" style="font-size: 14px">Shaoteng
                      Liu</a> -->
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
	</tbody>
  </table>
</body>

</html>
